# mutate(email_raw = paste(email_raw, collapse = ", "))
email_content <- email_content %>%
mutate(email_raw = toString(email_raw))
# mutate(email_raw = paste(email_raw, collapse = ", "))
parsed_data <- emails %>%
select(DocNumber) %>%
left_join(utc) %>%
left_join(sender) %>%
left_join(receiver) %>%
# left_join(cced) %>%
left_join(subject) %>%
left_join(email_content) %>%
na.omit()
write_feather(parsed_data, './email_data/parsed_email.feather')
fwrite(parsed_data, './email_data/parsed_emails.csv')
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 00_parse_emails
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
# library(tidyr)
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
library(quanteda)
tokenize <- quanteda::tokenize
library(data.table) # writes 17x faster to csv
library(feather)
# Load data -----------------------------------------------------------------------
emails <- read_csv("./email_data/Emails.csv")
aliases <- read_csv("./email_data/Aliases.csv")
receivers <- read_csv("./email_data/EmailReceivers.csv")
persons <- read_csv("./email_data/Persons.csv")
# Load data -----------------------------------------------------------------------
# There seems to be advantages to using the fields
# ExtractedTo over MetadataTo
# ExtractedFrom over MetadataFrom
# MetadataSubject over ExtractedSubject
# Clean date field
utc <- emails %>%
select(DocNumber, MetadataDateSent) %>%
mutate(date = format(as.POSIXct(MetadataDateSent,
format = "%F"),
format = "%m/%d/%Y")) %>%
select(-MetadataDateSent)
# Create Receiver by joining data from Persons df
receiver <- emails %>%
select(DocNumber, MetadataTo) %>%
mutate(receiver = MetadataTo) %>%
select(-MetadataTo) %>%
distinct() %>%
na.omit()
# Create Sender by joining data from Persons df
sender <- emails %>%
select(DocNumber, SenderPersonId, MetadataFrom, ExtractedFrom) %>%
left_join(persons, by = c("SenderPersonId" = "Id")) %>%
mutate(sender = Name) %>%
select(-SenderPersonId, -MetadataFrom, -ExtractedFrom, -Name) %>%
distinct() %>%
na.omit()
# Create CCed by joining data from Persons df
cced <- emails %>%
select(DocNumber, ExtractedCc) %>%
mutate(cced = ExtractedCc) %>%
# left_join(aliases, by = c("cced" = "Aliases")) %>%
select(-ExtractedCc) %>%
distinct() %>%
na.omit()
# Clean subject field
subject <- emails %>%
select(DocNumber, MetadataSubject) %>%
mutate(subject = MetadataSubject) %>%
select(-MetadataSubject)
# Clean email content ------------------------------------------------------------------
# Clean email main content field: apply tokeniser and remove stopwords
email_content <- emails %>%
select(DocNumber, ExtractedReleaseInPartOrFull, RawText) %>%
mutate(edited = ifelse(ExtractedReleaseInPartOrFull == "RELEASE IN FULL", 0, 1)) %>%
rowwise() %>%
mutate(email_raw = toLower(RawText, keepAcronyms = FALSE)) %>%
mutate(email_raw = tokenize(email_raw,
removePunct = TRUE,
removeSeparators = TRUE,
removeHyphens = TRUE,
removeNumbers = TRUE)) %>%
# mutate(email_raw = paste(email_raw, collapse = ", ")) %>%
select(-ExtractedReleaseInPartOrFull, -RawText)
# remove stopwords
email_content$email_raw <- removeFeatures(email_content$email_raw,
c(stopwords("english")))
# stem words and only keep unique words
email_content$email_raw <- wordstem(email_content$email_raw, language = "porter")
email_clean <- email_content %>%
rowwise() %>%
mutate(email_raw = toString(email_raw))
head(email_clean)
head(email_clean$email_raw)
parsed_data <- emails %>%
select(DocNumber) %>%
left_join(utc) %>%
left_join(sender) %>%
left_join(receiver) %>%
# left_join(cced) %>%
left_join(subject) %>%
left_join(email_clean) %>%
na.omit()
write_feather(parsed_data, './email_data/parsed_email.feather')
fwrite(parsed_data, './email_data/parsed_emails.csv')
write_feather(simple_data, './email_data/simplified_email.feather')
simple_data <- emails %>%
select(DocNumber) %>%
left_join(utc) %>%
left_join(email_clean) %>%
na.omit()
write_feather(simple_data, './email_data/simplified_email.feather')
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 01_create_event_dictionary
#
# Prepare working environment------------------------------------------------------
rm(list = ls()) # Clean up
library(tidyr)
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
library(quanteda)
tokenize <- quanteda::tokenize
# library(data.table) # writes 17x faster to csv
library(feather)
# Load data ---------------------------------------------------------------------------
# Tokenised vocabulary created with python scripts using the wikipedia api
# and python nltk module
event.vocab <- read_csv("./dictionary/event_vocab.csv")
# Clean vocabulary --------------------------------------------------------------------
# lowercase and tokenise vocabulary
event_dict <- event.vocab %>%
rowwise() %>%
mutate(dictionary = toLower(vocabulary, keepAcronyms = FALSE)) %>%
mutate(dictionary = tokenize(dictionary,
removePunct = TRUE,
removeSeparators = TRUE,
removeHyphens = TRUE,
removeNumbers = TRUE)) %>%
select(-vocabulary)
# remove stopwords
event_dict$dictionary <- removeFeatures(event_dict$dictionary,
c(stopwords("english")))
# stem words and only keep unique words
event_dict$dictionary <- wordstem(event_dict$dictionary, language = "porter")
# # Create DFM: Tokenise and remove symbols, numbers, stopwords
# event_dict <- dfm(event.vocab$vocabulary,
#                    ignoredFeatures = stopwords("english"),
#                    stem = TRUE,
#                    removePunct = TRUE,
#                    removeSeparators = TRUE,
#                    removeHyphens = TRUE,
#                    removeNumbers = TRUE) %>%
#   as.matrix() %>%
#   as.data.frame() %>%
#   add_rownames(var = 'event')
# Output ready dictionary dfm --------------------------------------------------------
# flatten word list for export to csv
event_dict <- event_dict %>%
mutate(dictionary = paste(dictionary, collapse = ", "))
write_feather(event_dict, './dictionary/parsed_dict.feather')
# fwrite(event_dict, './dictionary/parsed_dict.csv')
# rm(list= ls()[!(ls() %in% c('clean_email', 'clean_content', 'event_dict'))])
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 01_create_event_dictionary
#
# Prepare working environment------------------------------------------------------
rm(list = ls()) # Clean up
library(tidyr)
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
library(quanteda)
tokenize <- quanteda::tokenize
# library(data.table) # writes 17x faster to csv
library(feather)
# Load data ---------------------------------------------------------------------------
# Tokenised vocabulary created with python scripts using the wikipedia api
# and python nltk module
event.vocab <- read_csv("./dictionary/event_vocab.csv")
# Clean vocabulary --------------------------------------------------------------------
# lowercase and tokenise vocabulary
event_dict <- event.vocab %>%
rowwise() %>%
mutate(dictionary = toLower(vocabulary, keepAcronyms = FALSE)) %>%
mutate(dictionary = tokenize(dictionary,
removePunct = TRUE,
removeSeparators = TRUE,
removeHyphens = TRUE,
removeNumbers = TRUE)) %>%
select(-vocabulary)
# remove stopwords
event_dict$dictionary <- removeFeatures(event_dict$dictionary,
c(stopwords("english")))
# stem words and only keep unique words
event_dict$dictionary <- wordstem(event_dict$dictionary, language = "porter")
# # Create DFM: Tokenise and remove symbols, numbers, stopwords
# event_dict <- dfm(event.vocab$vocabulary,
#                    ignoredFeatures = stopwords("english"),
#                    stem = TRUE,
#                    removePunct = TRUE,
#                    removeSeparators = TRUE,
#                    removeHyphens = TRUE,
#                    removeNumbers = TRUE) %>%
#   as.matrix() %>%
#   as.data.frame() %>%
#   add_rownames(var = 'event')
# Output ready dictionary dfm --------------------------------------------------------
# flatten word list for export to csv
event_dict <- event_dict %>%
mutate(dictionary = paste(dictionary, collapse = ", "))
write_feather(event_dict, './parsed_data/parsed_dict.feather')
# fwrite(event_dict, './parsed_data/parsed_dict.csv')
# rm(list= ls()[!(ls() %in% c('clean_email', 'clean_content', 'event_dict'))])
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
cntrs <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
View(cntrs)
countries <- read_csv('./parsed_data/country_matches.csv')
View(countries)
coffee_long <- email.topics %>%
left_join(countries, by = cntry)
colnames(countries)
coffee_long <- email.topics %>%
left_join(countries, by = doc)
coffee_long <- email.topics %>%
left_join(countries, by = c(doc))
colnames(email.topics)
countries <- countries %>%
rename(DocNumber = doc)
colnames(countries)
coffee_long <- email.topics %>%
left_join(countries, by = c(DocNumber))
coffee_long <- email.topics %>%
left_join(countries)
?fill.na
?na
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
View(tableau.data)
tableau.data <- tableau.data %>%
mutate(cntry = ifelse(is.na(), "USA", cntry))
tableau.data <- tableau.data %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry))
View(tableau.data)
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
drop.na()
tableau.data <- tableau.data %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
colnames(tableau.data)
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
select(-continent, -region)
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
tableau.data <- tableau.data %>%
select(-continent, -region) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
select(-continent, -region) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
View(tableau.data)
colnames(tableau.data)
sum(tableau.data$_NA)
sum(tableau.data['_NA'])
sum(tableau.data[,c("_NA", "_arab_spring", "_benghazi", "_cancer", "_doctrine",
"_russian_reset", "_wiki_leak")])
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_ungrouped.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
sum(email.topics[,c("_NA", "_arab_spring", "_benghazi", "_cancer", "_doctrine",
"_russian_reset", "_wiki_leak")])
View(email.topics)
sum(email.topics[,c("_arab_spring", "_benghazi", "_cancer", "_doctrine",
"_russian_reset", "_wiki_leak")])
sum(tableau.data['_NA'])
sum(email.topics['_NA'])
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_undummied.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
select(-continent, -region, -edited_y) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
na.omit()
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
sum(email.topics[,c("_NA", "_arab_spring", "_benghazi", "_cancer", "_doctrine",
"_russian_reset", "_wiki_leak")])
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_undummied.csv')
countries <- countries %>%
rename(DocNumber = doc)
tableau.data <- email.topics %>%
left_join(countries)
colnames(tableau.data)
tableau.data <- tableau.data %>%
select(-continent, -region, -edited_y) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
rename(edited = edited_x)
na.omit()
tableau.data <- tableau.data %>%
select(-continent, -region, -edited_y) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
rename(edited = edited_x) %>%
na.omit()
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_undummied.csv')
# Rename for colnames to match
countries <- countries %>%
rename(DocNumber = doc)
# Join countries onto docNumbers
tableau.data <- email.topics %>%
left_join(countries)
tableau.data <- tableau.data %>%
select(-continent, -region, -edited_y) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
rename(edited = edited_x) %>%
na.omit()
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails
# Maria Athena B. Engesaeth
# 20_join_countries
#
# Prepare working environment------------------------------------------------------
# Clean up
rm(list = ls())
library(magrittr)
library(readr)
library(dplyr)
select <- dplyr::select
# Load data working environment------------------------------------------------------
countries <- read_csv('./parsed_data/country_matches.csv')
email.topics <- read_csv('./parsed_data/data_for_vis_undummied.csv')
View(email.topics)
colnames(email.topics)
tableau.data <- email.topics %>%
select(DocNumber, date, edited_x, email_topic) %>%
left_join(countries)
countries <- countries %>%
rename(DocNumber = doc)
tableau.data <- email.topics %>%
select(DocNumber, date, edited_x, email_topic) %>%
left_join(countries)
tableau.data <- tableau.data %>%
select(-continent, -region) %>%
mutate(cntry = ifelse(is.na(cntry), "USA", cntry)) %>%
rename(edited = edited_x) %>%
na.omit()
write_csv(tableau.data, './parsed_data/modified_for_tableau.csv')
