{
    "collab_server" : "",
    "contents" : "# Natural Language Processing - U.S. Secretary of State Hillary R. Clinton Emails\n# Maria Athena B. Engesaeth\n# 00_parse_emails\n#\n# Prepare working environment------------------------------------------------------\n\n# Clean up\nrm(list = ls())\n\n# library(tidyr)\nlibrary(magrittr)\nlibrary(readr)\nlibrary(dplyr)\nselect <- dplyr::select\nlibrary(quanteda)\ntokenize <- quanteda::tokenize\nlibrary(data.table) # writes 17x faster to csv\n\n# Load data -----------------------------------------------------------------------\n\nemails <- read_csv(\"./email_data/Emails.csv\")\naliases <- read_csv(\"./email_data/Aliases.csv\")\nreceivers <- read_csv(\"./email_data/EmailReceivers.csv\")\npersons <- read_csv(\"./email_data/Persons.csv\")\n\n\n# Load data -----------------------------------------------------------------------\n\n# There seems to be advantages to using the fields\n# ExtractedTo over MetadataTo\n# ExtractedFrom over MetadataFrom\n# MetadataSubject over ExtractedSubject\n\n\n# Clean date field\nutc <- emails %>% \n  select(DocNumber, MetadataDateSent) %>%\n  mutate(date = format(as.POSIXct(MetadataDateSent,\n                                  format = \"%F\"),\n                       format = \"%m/%d/%Y\")) %>% \n  select(-MetadataDateSent)\n\n\n# Create Receiver by joining data from Persons df\nreceiver <- emails %>% \n  select(DocNumber, MetadataTo) %>% \n  mutate(receiver = MetadataTo) %>% \n  select(-MetadataTo) %>% \n  distinct() %>% \n  na.omit()\n\n\n# Create Sender by joining data from Persons df\nsender <- emails %>% \n  select(DocNumber, SenderPersonId, MetadataFrom, ExtractedFrom) %>% \n  left_join(persons, by = c(\"SenderPersonId\" = \"Id\")) %>% \n  mutate(sender = Name) %>% \n  select(-SenderPersonId, -MetadataFrom, -ExtractedFrom, -Name) %>% \n  distinct() %>% \n  na.omit()\n\n\n# Create CCed by joining data from Persons df\ncced <- emails %>% \n  select(DocNumber, ExtractedCc) %>% \n  mutate(cced = ExtractedCc) %>% \n  # left_join(aliases, by = c(\"cced\" = \"Aliases\")) %>% \n  select(-ExtractedCc) %>% \n  distinct() %>% \n  na.omit()\n\n\n# Clean subject field\nsubject <- emails %>% \n  select(DocNumber, MetadataSubject) %>% \n  mutate(subject = MetadataSubject) %>% \n  select(-MetadataSubject)\n\n\n# Clean email content ------------------------------------------------------------------\n# Clean email main content field: apply tokeniser and stem words\n\nclean_email <- emails %>%\n  select(DocNumber, ExtractedReleaseInPartOrFull, RawText) %>% \n  mutate(edited = ifelse(ExtractedReleaseInPartOrFull == \"RELEASE IN FULL\", 0, 1)) %>% \n  mutate(email_raw = RawText) %>% \n  # rowwise() %>%\n  # mutate(RawText = tokenize(RawText,\n  #                             removePunct = TRUE,\n  #                             removeSeparators = TRUE,\n  #                             removeHyphens = TRUE,\n  #                             removeNumbers = TRUE)) %>%\n  # mutate(email_raw = removeFeatures(RawText, c(stopwords(\"english\")))) %>%\n  # mutate(email_raw = paste(email_raw, collapse = \", \")) %>%\n  select(-ExtractedReleaseInPartOrFull, -RawText)\n  \n\n# Create quanteda corpus from email content from PDF extract\nemail.corpus <- corpus(clean_email$email_raw,\n                       docvars = emails[c(1, 2)],\n                       docnames = emails$DocNumber)\n\n# Create DFM: Tokenise and remove symbols, numbers, stopwords\nclean_content <- dfm(email.corpus,\n                   ignoredFeatures = stopwords(\"english\"),\n                   stem = TRUE,\n                   removePunct = TRUE,\n                   removeSeparators = TRUE,\n                   removeHyphens = TRUE,\n                   removeNumbers = TRUE) %>%\n  as.matrix() %>%\n  as.data.frame() %>%\n  add_rownames(var = 'DocNumber')\n\n# Join dataframes to output -----------------------------------------------------------\n\n# Cleaned dataframe to output\nparsed_data <- emails %>% \n  select(DocNumber) %>% \n  left_join(utc) %>% \n  left_join(sender) %>% \n  left_join(receiver) %>% \n  # left_join(cced) %>% \n  left_join(subject) %>% \n  left_join(clean_email) %>% \n  select(-email_raw) %>%\n  left_join(clean_content, by = 'DocNumber') %>% \n  na.omit()\n\nrm(list= ls()[!(ls() %in% c('parsed_data'))])\n\n# Output to csv\nfwrite(parsed_data, './email_data/parsed_emails.csv')\n# write_csv(parsed_data, './email_data/parsed_emails.csv')\n\nrm(list = ls())\ngc()\n",
    "created" : 1464338981884.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1053285729",
    "id" : "33A11ED",
    "lastKnownWriteTime" : 1464345226,
    "last_content_update" : 1464345226870,
    "path" : "~/Repositories/kaggle_projects/nlp_clinton_emails/r/00_parse_emails.R",
    "project_path" : "r/00_parse_emails.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}